#!/usr/bin/env python3
"""Basic LLM integration test."""

import asyncio
from llm_client import get_llm_client

async def test_basic_llm():
    """Test basic LLM functionality."""
    print("ğŸ§ª Testing basic LLM integration...")
    
    try:
        # Test client initialization
        llm_client = get_llm_client()
        print(f"  âœ… LLM client initialized: {llm_client.primary_provider.value}")
        
        # Test simple request
        response = await llm_client._make_llm_request(
            prompt="Return the JSON: {\"test\": \"success\", \"number\": 42}",
            max_tokens=50,
            temperature=0.0
        )
        
        print(f"  âœ… LLM request: success={response.success}")
        if response.success:
            print(f"  âœ… Response: {response.content[:100]}...")
            print(f"  âœ… Provider: {response.provider.value}")
            print(f"  âœ… Model: {response.model}")
            if response.tokens_used:
                print(f"  âœ… Tokens: {response.tokens_used}")
        else:
            print(f"  âŒ Error: {response.error}")
        
        return response.success
        
    except Exception as e:
        print(f"  âŒ Test failed: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(test_basic_llm())
    if success:
        print("\nğŸ‰ LLM integration working!")
    else:
        print("\nâŒ LLM integration failed")
    exit(0 if success else 1)